## Data Directory Structure

In a Kedro project, the `data` directory is organized into several subfolders,
each serving a specific purpose in the data pipeline. This structure helps
maintain a clear workflow from raw data to final outputs. Hereâ€™s an overview of
what each subfolder is typically used for:

- **`data/01_raw/`**: This folder contains the original datasets as they are
  received. These files are unprocessed and serve as the starting point for the
  data pipeline.

- **`data/02_intermediate/`**: This folder is used to store datasets that have
  undergone some initial processing. These datasets are not yet ready for
  modeling but have been cleaned or transformed in some way.

- **`data/03_primary/`**: This folder holds datasets that are prepared for
  feature extraction. The data here is in a state suitable for further
  transformation into features.

- **`data/04_feature/`**: This folder contains datasets that have been
  transformed into features ready for modeling. These datasets are the result of
  feature engineering and selection processes.

- **`data/05_model_input/`**: This folder is for datasets that are directly used
  as inputs to train machine learning models. It typically includes both
  features and labels.

- **`data/06_models/`**: This folder is designated for storing trained model
  artifacts. This can include serialized model files and any other relevant
  model data.

- **`data/07_model_output/`**: This folder stores the output generated by
  models, such as predictions or evaluation metrics.

- **`data/08_reporting/`**: This folder is used for datasets that are intended
  for reporting purposes. It might include summary statistics, visualizations,
  or other forms of data used to communicate results.

This structured approach ensures that data flows logically through the pipeline,
from raw input to final outputs, facilitating easier project maintenance and
scalability.
